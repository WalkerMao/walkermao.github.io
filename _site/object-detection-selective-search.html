<!DOCTYPE html>
<html lang="en">
  <head>
    <script src="https://kit.fontawesome.com/123ecac47c.js" crossorigin="anonymous"></script><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/assets/css/style.css">
<link rel="shortcut icon" type="image/png" href="/assets/portfolio.png">
<title>Object Detection: Selective Search</title>
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Object Detection: Selective Search | Weikai’s blog.</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Object Detection: Selective Search" />
<meta name="author" content="Weikai Mao" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The contents in this post are excerpted from the paper “Selective Search for Object Recognition” 1, with a little bit modification, as my notes for this great paper. Uijlings, Jasper RR, Koen EA Van De Sande, Theo Gevers, and Arnold WM Smeulders. “Selective search for object recognition.” International journal of computer vision 104, no. 2 (2013): 154-171. &#8617;" />
<meta property="og:description" content="The contents in this post are excerpted from the paper “Selective Search for Object Recognition” 1, with a little bit modification, as my notes for this great paper. Uijlings, Jasper RR, Koen EA Van De Sande, Theo Gevers, and Arnold WM Smeulders. “Selective search for object recognition.” International journal of computer vision 104, no. 2 (2013): 154-171. &#8617;" />
<link rel="canonical" href="http://localhost:4000/object-detection-selective-search.html" />
<meta property="og:url" content="http://localhost:4000/object-detection-selective-search.html" />
<meta property="og:site_name" content="Weikai’s blog." />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-11-28T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Object Detection: Selective Search" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Weikai Mao"},"dateModified":"2021-11-28T00:00:00+08:00","datePublished":"2021-11-28T00:00:00+08:00","description":"The contents in this post are excerpted from the paper “Selective Search for Object Recognition” 1, with a little bit modification, as my notes for this great paper. Uijlings, Jasper RR, Koen EA Van De Sande, Theo Gevers, and Arnold WM Smeulders. “Selective search for object recognition.” International journal of computer vision 104, no. 2 (2013): 154-171. &#8617;","headline":"Object Detection: Selective Search","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/object-detection-selective-search.html"},"url":"http://localhost:4000/object-detection-selective-search.html"}</script>
<!-- End Jekyll SEO tag -->


<meta name="google-site-verification" content="wXp8C1QlYKCpKxfXyFfQXEv9l5fJvcOi53ofYmOcaSA" />
<meta name="msvalidate.01" content="97F0BB32D312B808156DE357EA8474D3" />
<meta name="yandex-verification" content="690106a82d8966ab" />

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ["$","$"], ["\\(","\\)"] ],
        displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno"
      }
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>    


  







</head>
  <body>
    <main class="container">
      <section class="about">
        <a href="/" class="iconlink"> 
          <h3> 
            <i class="fas fa-home"></i> HOME 
          </h3> 
        </a>
        <a href="/"> <img src="/assets/portfolio.png" alt="Weikai Mao"></a>
        <h2 id="title"> Weikai Mao </h2>
        <p style="font-size:90%" class="tagline">maoweikai123@outlook.com</p>
        
        <ul class="social"><a href="https://github.com/WalkerMao">
              <li>
                <i class="fab fa-github"></i>
              </li>
            </a><a href="https://www.linkedin.com/in/weikai-mao-000249124">
              <li>
                <i class="fab fa-linkedin"></i>
              </li>
            </a><a href="/wechat-qr-code.html">
              <li>
                <i class="fab fa-weixin"></i>
              </li>
            </a></ul><h3 style="color:gray; font-weight:normal"> Categories: </h3>
            <ul class="post-categories" style="max-width:225px;">
              
                  <a class="post-link" href="/"> <li style="padding: 4px 8px;"> All </li> </a>
              
                  <a class="post-link" href="/categories/cs"> <li style="padding: 4px 8px;"> CS </li> </a>
              
                  <a class="post-link" href="/categories/cv"> <li style="padding: 4px 8px;"> CV </li> </a>
              
                  <a class="post-link" href="/categories/dl"> <li style="padding: 4px 8px;"> DL </li> </a>
              
                  <a class="post-link" href="/categories/fe"> <li style="padding: 4px 8px;"> FE </li> </a>
              
                  <a class="post-link" href="/categories/math"> <li style="padding: 4px 8px;"> Math </li> </a>
              
                  <a class="post-link" href="/categories/ml"> <li style="padding: 4px 8px;"> ML </li> </a>
              
                  <a class="post-link" href="/categories/nlp"> <li style="padding: 4px 8px;"> NLP </li> </a>
              
                  <a class="post-link" href="/categories/stat"> <li style="padding: 4px 8px;"> Stat </li> </a>
              
                  <a class="post-link" href="/categories/杂"> <li style="padding: 4px 8px;"> 杂 </li> </a>
              
            </ul><p>&copy; 2023 </p>

      </section>
      <section class="content">
        <div class="sidebar">
  <ul><li><a href="#abstract">Abstract</a></li><li><a href="#1-introduction">1 Introduction</a><ul><li><a href="#11-segmentation">1.1 Segmentation</a></li><li><a href="#12--exhaustive-search">1.2  Exhaustive Search</a></li><li><a href="#13-inspired-by-these-two-approaches">1.3 Inspired by These Two Approaches</a></li></ul></li><li><a href="#2-related-work">2 Related Work</a><ul><li><a href="#21--exhaustive-search">2.1  Exhaustive Search</a></li><li><a href="#22-segmentation">2.2 Segmentation</a></li><li><a href="#23-other-sampling-strategies">2.3 Other Sampling Strategies</a></li><li><a href="#24-novelty-of-selective-search">2.4 Novelty of Selective Search</a></li></ul></li><li><a href="#3-selective-search">3 Selective Search</a><ul><li><a href="#31-selective-search-by-hierarchical-grouping">3.1 Selective Search by Hierarchical Grouping</a></li><li><a href="#32-diversification-strategies">3.2 Diversification Strategies</a><ul><li><a href="#321-complementary-colour-spaces">3.2.1 Complementary Colour Spaces</a></li><li><a href="#322-complementary-similarity-measures">3.2.2 Complementary Similarity Measures</a></li><li><a href="#323-complementary-starting-regions">3.2.3 Complementary Starting Regions</a></li></ul></li><li><a href="#33-combining-locations">3.3 Combining Locations</a></li></ul></li><li><a href="#summary">Summary</a></li></ul>

</div><div class="post-container" id="viewpoint">
  <a class="post-link" href="/object-detection-selective-search.html">
    <h2 class="post-title">Object Detection: Selective Search</h2>
  </a>
  <div class="post-meta">
    <div>
      <ul class="post-categories"><a class="post-link" href="/categories/cv"> <li>CV</li> </a></ul>
      <ul class="post-tags"><a class="post-link" href="/tags/object detection"> <li>Object detection</li> </a><a class="post-link" href="/tags/traditional cv"> <li>Traditional CV</li> </a></ul>
    </div>
    <div class="post-date">
      <i class="icon-calendar"></i>
      Nov 28, 2021
    </div>
  </div>
  <div style="line-height:77%;">
    <br>
  </div>
  <div class="post"><p>The contents in this post are excerpted from the paper “Selective Search for Object Recognition” <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>, with a little bit modification, as my notes for this great paper.</p>

<h2 id="abstract">Abstract</h2>

<p>This paper addresses the problem of <strong>generating possible object locations for use in object recognition</strong>. The authors introduce selective search which combines the strength of both an exhaustive search and segmentation. Like segmentation, the selective search uses the image structure to guide our sampling process. Like exhaustive search, the selective search aims to capture all possible object locations.</p>

<h2 id="1-introduction">1 Introduction</h2>

<p>As for the problem of generating possible object locations for use in object recognition, there are two main approaches: segmentation and exhaustive search.</p>

<h3 id="11-segmentation">1.1 Segmentation</h3>

<p>For a long time, objects were sought to be delineated before their identification. This gave rise to segmentation, which aims for a unique partitioning of the image through a generic algorithm.</p>

<p>Three problems for segmentation based methods:</p>

<ol>
  <li>Images are intrinsically hierarchical (e.g. a spoon in a bowl and the bowl on a table). This is most naturally addressed by using a hierarchical partitioning.</li>
  <li>Individual visual features (e.g. colour, texture) cannot resolve the ambiguity of segmentation.</li>
  <li>Regions with very different characteristics, such as a face over a sweater. Without prior recognition it is hard to decide that a face and a sweater are part of one object.</li>
</ol>

<div align="center">
<figure>
<img src="https://d3i71xaburhd42.cloudfront.net/38b6540ddd5beebffd05047c78183f7575559fb2/2-Figure1-1.png" alt="Figure 1" style="zoom:70%;" />
<figcaption style="font-size:80%;"> Figure 1: There is a high variety of reasons that an image region forms an object. In (b) the cats can be distinguished by colour, not texture. In (c) the chameleon can be distinguished from the surrounding leaves by texture, not colour. In (d) the wheels can be part of the car because they are enclosed, not because they are similar in texture or colour. Therefore, to find objects in a structured way it is necessary to use a variety of diverse strategies. Furthermore, an image is intrinsically hierarchical as there is no single scale for which the complete table, salad bowl, and salad spoon can be found in (a). (<a href="https://www.semanticscholar.org/paper/Selective-Search-for-Object-Recognition-Uijlings-Sande/38b6540ddd5beebffd05047c78183f7575559fb2/figure/0">Source</a>) </figcaption>
</figure>
</div>

<h3 id="12--exhaustive-search">1.2  Exhaustive Search</h3>

<p>Exhaustive search examines every location within the image as to not miss any potential object location. However, the search space is too huge and it has to be reduced by using restrictions like a regular grid, fixed scales, and fixed aspect ratios etc..</p>

<p>Rather then sampling locations blindly using an exhaustive search, a key question is: Can we steer the sampling by a data-driven analysis?</p>

<h3 id="13-inspired-by-these-two-approaches">1.3 Inspired by These Two Approaches</h3>

<p>In this paper, we aim to combine the best of the intuitions of segmentation and exhaustive search and propose a data-driven selective search. Inspired by bottom-up segmentation, we aim to exploit the structure of the image to generate object locations. Inspired by exhaustive search, we aim to capture all possible object locations. Therefore, instead of using a single sampling technique, we aim to diversify the sampling techniques to account for as many image conditions as possible.</p>

<p>Specifically, we use a data-driven grouping based strategy where we increase diversity by using a variety of complementary grouping criteria and a variety of complementary colour spaces with different invariance properties. The set of locations is obtained by combining the locations of these complementary partitionings.</p>

<p>Our goal is to generate a class-independent, data-driven, selective search strategy that generates a small set of high-quality object locations.</p>

<h2 id="2-related-work">2 Related Work</h2>

<h3 id="21--exhaustive-search">2.1  Exhaustive Search</h3>

<p>Sliding window techniques use a coarse search grid and fixed aspect ratios, using weak classifiers and economic image features such as HOG. For example, the HOG + SVM algorithm uses the HOG feature vector of a window as an input to the trained SVM to decide whether the window contains a (part of) target object.</p>

<p>Branch and bound technique uses the appearance model to guide the search.</p>

<h3 id="22-segmentation">2.2 Segmentation</h3>

<h3 id="23-other-sampling-strategies">2.3 Other Sampling Strategies</h3>

<h3 id="24-novelty-of-selective-search">2.4 Novelty of Selective Search</h3>

<ul>
  <li>
    <p>Instead of an exhaustive search, we use segmentation as selective search yielding a small set of class independent object locations.</p>
  </li>
  <li>
    <p>Instead of the segmentation methods that focus on the best segmentation algorithm, we use a variety of strategies to deal with as many image conditions as possible.</p>
  </li>
  <li>
    <p>Instead of learning an objectness measure on randomly sampled boxes , we use a bottom-up grouping procedure to generate good object locations.</p>
  </li>
</ul>

<h2 id="3-selective-search">3 Selective Search</h2>

<p>Design considerations of selective search:</p>

<ul>
  <li>Capture all scales (by hierarchical grouping).</li>
  <li>Diversification. We use a diverse set of strategies (colour, texture, size, and fill) to deal with all cases.</li>
  <li>Fast to compute. (it’s fast at that time)</li>
</ul>

<h3 id="31-selective-search-by-hierarchical-grouping">3.1 Selective Search by Hierarchical Grouping</h3>

<p>Our grouping procedure now works as follows. We first use “<a href="https://link.springer.com/article/10.1023/B:VISI.0000022288.19776.77">Felzenszwalb and Huttenlocher (2004)</a>” to create initial regions. Then we use a greedy algorithm to iteratively group regions together: First the similarities between all neighbouring regions are calculated. The two most similar regions are grouped together, and new similarities are calculated between the resulting region and its neighbours. The process of grouping the most similar regions is repeated until the whole image becomes a single region. The general method is detailed in Algorithm 1.</p>

<div align="center">
<figure>
<img src="https://lilianweng.github.io/lil-log/assets/images/selective-search-algorithm.png" alt="Selective Search Algorithm" style="zoom: 45%;" />
</figure>
</div>

<p>For the similarity \(s(r_i, r_j)\) between region \(r_i\) and \(r_j\) we want a variety of complementary measures under the constraint that they are fast to compute. In effect, this means that the similarities should be based on features that can be propagated through the hierarchy, i.e. when merging region \(r_i\) and \(r_j\) into \(r_t\), the features of region \(r_t\) need to be calculated from the features of \(r_i\) and \(r_j\) without accessing the image pixels.</p>

<div align="center">
<figure>
<img src="https://d3i71xaburhd42.cloudfront.net/38b6540ddd5beebffd05047c78183f7575559fb2/4-Figure2-1.png" alt="Figure 2" style="zoom:80%;" />
<figcaption style="font-size:80%;"> Figure 2: The left image both in (a) and (b) illustrates the initial regions (or the regions after a few groupings), and the middle illustrates the regions after some groupings, and the right illustrates more groupings. (<a href="https://www.semanticscholar.org/paper/Selective-Search-for-Object-Recognition-Uijlings-Sande/38b6540ddd5beebffd05047c78183f7575559fb2/figure/2">Source</a>) </figcaption>
</figure>
</div>

<h3 id="32-diversification-strategies">3.2 Diversification Strategies</h3>

<p>We diversify our selective search by (1) using a variety of colour spaces with different invariance properties, (2) using different similarity measures \(s_{ij}\), and (3) varying our starting regions.</p>

<h4 id="321-complementary-colour-spaces">3.2.1 Complementary Colour Spaces</h4>

<p>We want to account for different scene and lighting conditions. Therefore we perform our hierarchical grouping algorithm in a variety of colour spaces with a range of invariance properties (table 1): \(\text{RGB}\), intensity (grey-scale) \(I\), \(\text{Lab}\), \(\text{HSV}\), …</p>

<div align="center">
<figure>
<img src="https://d3i71xaburhd42.cloudfront.net/38b6540ddd5beebffd05047c78183f7575559fb2/5-Table1-1.png" alt="Table 1" style="zoom: 65%;" />
<figcaption style="font-size:80%;"> Table 1: The invariance properties of both the individual colour channels and the colour spaces used in this paper, sorted by degree of invariance. A “+/-” means partial invariance. A fraction 1/3 means that one of the three colour channels is invariant to said property. (<a href="https://www.semanticscholar.org/paper/Selective-Search-for-Object-Recognition-Uijlings-Sande/38b6540ddd5beebffd05047c78183f7575559fb2/figure/1">Source</a>) </figcaption>
</figure>
</div>

<h4 id="322-complementary-similarity-measures">3.2.2 Complementary Similarity Measures</h4>

<p>We define four complementary, fast-to-compute similarity measures (read the paper for detail):</p>

<ul>
  <li>\(s_{\text{colour}}(r_i, r_j)\) measures colour similarity;</li>
  <li>\(s_{\text{texture}}(r_i, r_j)\) measures texture similarity;</li>
  <li>\(s_{\text{size}}(r_i, r_j)\) encourages small regions to merge early. It prevents a single region from gobbling up all other regions one by one.</li>
  <li>\(s_{\text{fill}}(r_i, r_j)\) measures how well region \(r_i\) and \(r_j\) fit into each other.</li>
</ul>

<p>In this paper, our final similarity measure is a combination of the above four:</p>

\[\begin{aligned}
s\left(r_{i}, r_{j}\right) = &amp;\ a_{1} s_{\text{colour}}\left(r_{i}, r_{j}\right)+a_{2} s_{\text {texture }}\left(r_{i}, r_{j}\right) \\
&amp;+ a_{3} s_{\text{size}}\left(r_{i}, r_{j}\right)+a_{4} s_{\text{fill}}\left(r_{i}, r_{j}\right),
\end{aligned}\]

<p>where \(a_{i} \in\{0,1\}\) denotes if the similarity measure is used or not.</p>

<h4 id="323-complementary-starting-regions">3.2.3 Complementary Starting Regions</h4>

<p>Different starting regions are (already) obtained by varying the colour spaces, each which has different invariance properties. Additionally, we vary the threshold parameter \(k\) in “<a href="https://link.springer.com/article/10.1023/B:VISI.0000022288.19776.77">Felzenszwalb and Huttenlocher (2004)</a>”.</p>

<h3 id="33-combining-locations">3.3 Combining Locations</h3>

<p>In this paper, we combine the object hypotheses of several variations of our hierarchical grouping algorithm. Ideally, we want to order the object hypotheses in such a way that the locations which are most likely to be an object come first.</p>

<p>We choose to order the combined object hypotheses set based on the order in which the hypotheses were generated in each individual grouping strategy. That means earlier grouped regions (lower hierarchy) are more possible to be an object. However, as we combine results from up to 80 different strategies, such order would too heavily emphasize large regions, because larger regions are more possible to appear in different grouping strategies. To prevent this, we include some randomness as follows.</p>

<p>Given a grouping strategy \(s\), let \(r_{h}^{s}\) be the region which is created at position \(h\) in the hierarchy, where \(h=1\) represents the top of the hierarchy (whose corresponding region covers the complete image). We now calculate the position value \(v_{h}^{s}\) as \(\text{RND} \times h\), where \(\text{RND}\) is a random number in range \([0,1]\). The final ranking is obtained by ordering the regions using \(v_{h}^{s}\).</p>

<p>Thus, the possibility score of a region \(r\) to be an object is</p>

\[\begin{aligned}
\text{score}(r) &amp;= \sum_{s,h} \mathbb{1}(r_{h}^{s}=r) \cdot \text{score}(r_{h}^{s}) \\
&amp;= \sum_{s,h} \mathbb{1}(r_{h}^{s}=r) \cdot v_{h}^{s} \\
&amp;= \sum_{s,h} \mathbb{1}(r_{h}^{s}=r) \cdot \text{RND} \cdot h.
\end{aligned}\]

<h2 id="summary">Summary</h2>

<p>To generate class-independent object locations, “selective search” initialize regions by “<a href="https://link.springer.com/article/10.1023/B:VISI.0000022288.19776.77">Felzenszwalb and Huttenlocher (2004)</a>” and do hierarchical grouping (algorithm 1) with diversification strategies, then order the object hypotheses (regions, locations) by the possibility to be an object.</p>

<p><br /></p>

<p><strong>Reference:</strong></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Uijlings, Jasper RR, Koen EA Van De Sande, Theo Gevers, and Arnold WM Smeulders. “Selective search for object recognition.” <em>International journal of computer vision</em> 104, no. 2 (2013): 154-171. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div>

  <br> </br>
  <p><font color="grey" size="4"> Comments </font></p>
  <HR color=#D1D0CE SIZE=10>

<div id="disqus_thread"></div>

<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://walkermao.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


                            

  
</div>

      </section>
    </main><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178951885-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178951885-1');
</script>

    
    <div id="back-top">
      <a href="javascript:void(0);" onclick="topFunction()" title="Back to top"> </a>
    </div>

  </body>
</html>

<script src = "/assets/js/scroll_into_view.js"></script>
<script src = "/assets/js/back_to_top.js"></script>